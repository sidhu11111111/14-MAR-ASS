{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c2e5b01",
   "metadata": {},
   "source": [
    " #QNO.1 ANS \n",
    " 1.Independence: The observations within each group are assumed to be independent of each other.\n",
    "2.Normality: The dependent variable follows a normal distribution within each group. This assumption is more important when the group sizes are small.\n",
    "3.Homogeneity of variances: The variability (variance) of the dependent variable is assumed to be equal across all groups.\n",
    "Violations that could impact the validity of ANOVA results:\n",
    "\n",
    "Violation of independence: If the observations within groups are not independent, such as in a repeated measures design or a 1.clustered data structure, the assumption is violated.\n",
    "2.Violation of normality: If the dependent variable is not normally distributed within each group, the results may be unreliable, especially when the sample sizes are small.\n",
    "3.Violation of homogeneity of variances: If the variability of the dependent variable is not equal across groups (i.e., groups have unequal variances), the results of ANOVA may be affected. This is known as heteroscedasticity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c231365",
   "metadata": {},
   "source": [
    "#QNO.2\n",
    " The three types of ANOVA are:\n",
    "\n",
    "1.One-Way ANOVA: This type of ANOVA is used when you have one categorical independent variable (also known as a factor) and one continuous dependent variable. It is used to determine whether there are any significant differences between the means of two or more groups.\n",
    "\n",
    "2.Two-Way ANOVA: This type of ANOVA is used when you have two independent variables (factors) and one continuous dependent variable. It is used to analyze the main effects of each independent variable and the interaction effect between them.\n",
    "\n",
    "3.Multivariate ANOVA (MANOVA): This type of ANOVA is used when you have multiple dependent variables and one or more independent variables. It allows you to examine the differences between groups across multiple dependent variables simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9374e",
   "metadata": {},
   "source": [
    "#QNO.3 ANS\n",
    " The partitioning of variance in ANOVA refers to the division of the total variability in the data into different components. These components include the explained variance (also known as the between-group variance), the unexplained variance (also known as the within-group variance or residual variance), and the total variance.\n",
    "\n",
    "It is important to understand this concept because it helps us quantify the amount of variance that can be attributed to the factors being tested in ANOVA. By decomposing the total variability into these components, we can assess the significance of the factors and determine their contribution to the overall variability in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9295453a",
   "metadata": {},
   "source": [
    "#QNO.4 ANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "092e618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of squares (SST): 15.999999999999996\n",
      "Explained sum of squares (SSE): 1.5\n",
      "Residual sum of squares (SSR): 14.499999999999996\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "data = {'group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "        'value': [1, 2, 3, 4, 5, 6]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "model = ols('value ~ group', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "SST = anova_table['sum_sq']['group']\n",
    "SSE = anova_table['sum_sq']['Residual']\n",
    "SSR = SST - SSE\n",
    "\n",
    "print('Total sum of squares (SST):', SST)\n",
    "print('Explained sum of squares (SSE):', SSE)\n",
    "print('Residual sum of squares (SSR):', SSR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f29b52e",
   "metadata": {},
   "source": [
    "#QNO.5 ANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f38d11e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of squares (SST): 15.999999999999996\n",
      "Explained sum of squares (SSE): 1.5\n",
      "Residual sum of squares (SSR): 14.499999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\74809\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\anova.py:138: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  (model.ssr / model.df_resid))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "data = {'group1': ['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "        'group2': ['X', 'Y', 'Z', 'X', 'Y', 'Z'],\n",
    "        'value': [1, 2, 3, 4, 5, 6]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "model = ols('value ~ group1 + group2 + group1:group2', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "main_effect_group1 = anova_table['sum_sq']['group1']\n",
    "main_effect_group2 = anova_table['sum_sq']['group2']\n",
    "\n",
    "print('Total sum of squares (SST):', SST)\n",
    "print('Explained sum of squares (SSE):', SSE)\n",
    "print('Residual sum of squares (SSR):', SSR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15afefc",
   "metadata": {},
   "source": [
    "#QNO.5 ANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2722f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'factor1': [1, 1, 2, 2, 3, 3],\n",
    "    'factor2': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
    "    'response': [5, 3, 6, 2, 7, 4]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "model = ols('response ~ factor1 + factor2 + factor1:factor2', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "main_effect_factor1 = anova_table['sum_sq']['factor1']\n",
    "main_effect_factor2 = anova_table['sum_sq']['factor2']\n",
    "\n",
    "interaction_effect = anova_table['sum_sq']['factor1:factor2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d857f540",
   "metadata": {},
   "source": [
    "#QNO.6 ANS\n",
    "In a one-way ANOVA, an F-statistic tests the null hypothesis that the means of all the groups are equal, against the alternative hypothesis that at least one of the means is different. A p-value of 0.02 suggests that the probability of observing such a large F-statistic under the null hypothesis is 0.02, assuming the usual significance level of 0.05.\n",
    "\n",
    "If the p-value is less than the significance level, we reject the null hypothesis and conclude that there is evidence of at least one group mean being different from the others. In this case, with a p-value of 0.02, we reject the null hypothesis and conclude that there is significant evidence that the means of the groups are different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec30902",
   "metadata": {},
   "source": [
    "# QNO.7 ANS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317756cd",
   "metadata": {},
   "source": [
    "1.Complete Case Analysis: This approach involves excluding any cases with missing data from the analysis. However, this may lead to a loss of statistical power and potential bias if the missing data are not missing completely at random (MCAR).\n",
    "\n",
    "2.Pairwise Deletion: In this approach, missing values are ignored for each pairwise comparison. It can be used when missing data occur in only a few observations. However, this approach may introduce bias if the missing data are related to the outcome or other variables.\n",
    "\n",
    "3.Imputation: Imputation involves estimating missing values based on observed data. Common imputation methods include mean imputation, regression imputation, or multiple imputation. Imputation can help retain sample size and reduce bias, but the accuracy of imputed values depends on the imputation method used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827e8b6e",
   "metadata": {},
   "source": [
    "#QNO.8 ANS\n",
    "After conducting an ANOVA and finding a significant overall effect, post-hoc tests are often used to determine which specific group means differ significantly from each other. Some common post-hoc tests include:\n",
    "\n",
    "1.Tukey's Honestly Significant Difference (HSD): Tukey's HSD test compares all possible pairs of group means while controlling the family-wise error rate. It is suitable when you have a balanced design (equal sample sizes) and want to compare all group means against each other.\n",
    "\n",
    "2.Bonferroni correction: The Bonferroni correction adjusts the significance level for each pairwise comparison to maintain an overall family-wise error rate. It is suitable when you want to control for multiple comparisons and have a predetermined significance level.\n",
    "\n",
    "3.Scheffe's test: Scheffe's test is a conservative post-hoc test that allows for comparing all possible group mean differences while controlling the family-wise error rate. It is suitable when you have unequal sample sizes and want to compare all group means against each other.\n",
    "\n",
    "4.Dunnett's test: Dunnett's test compares each treatment group mean against a control group mean. It is suitable when you have a control group and want to determine if any treatment groups differ significantly from the control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54c1e9",
   "metadata": {},
   "source": [
    "#QNO. 9 ANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "338f09c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 88.36679842865402\n",
      "p-value: 8.987500355979926e-22\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "diet_A = [2.3, 1.8, 3.1, 1.5, 2.6, 2.0, 2.7, 2.2, 1.9, 2.4, 1.7, 2.8, 1.6, 2.5, 1.9, 2.1, 2.3, 1.8, 2.0, 2.4, 1.5, 2.7, 2.9, 1.8, 2.3, 2.2, 1.9, 2.5, 2.1, 1.7]\n",
    "diet_B = [1.3, 0.8, 1.1, 1.5, 0.6, 0.9, 1.2, 1.4, 1.0, 0.7, 1.1, 1.2, 0.8, 1.3, 1.2, 0.9, 1.5, 1.4, 0.6, 1.3, 1.1, 1.0, 1.4, 1.3, 0.9, 1.2, 0.8, 1.5, 1.1, 1.3]\n",
    "diet_C = [1.7, 1.5, 1.8, 1.3, 1.4, 1.2, 1.9, 1.6, 1.7, 1.5, 1.3, 1.6, 1.4, 1.8, 1.7, 1.5, 1.2, 1.4, 1.3, 1.6, 1.5, 1.7, 1.6, 1.4, 1.3, 1.5, 1.7, 1.8, 1.6, 1.5, 1.9]\n",
    "\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f8e37e",
   "metadata": {},
   "source": [
    "#QNO.10 ANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f399ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformula\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ols\n\u001b[0;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProgram\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperience\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m              \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m16\u001b[39m]\n\u001b[0;32m     17\u001b[0m }\n\u001b[1;32m---> 19\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m ols(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime ~ C(Program) + C(Experience) + C(Program):C(Experience)\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mdf)\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m     23\u001b[0m anova_table \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39manova_lm(model, typ\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "data = {\n",
    "    'Program': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
    "    'Experience': ['Novice'] * 30 + ['Experienced'] * 30 + ['Novice'] * 30 + ['Experienced'] * 30,\n",
    "    'Time': [10, 12, 14, 11, 13, 15, 12, 14, 16, 9, 11, 13, 10, 12, 14, 11, 13, 15, 12, 14, 16,\n",
    "             9, 11, 13, 10, 12, 14, 11, 13, 15, 12, 14, 16,\n",
    "             9, 11, 13, 10, 12, 14, 11, 13, 15, 12, 14, 16,\n",
    "             9, 11, 13, 10, 12, 14, 11, 13, 15, 12, 14, 16,\n",
    "             9, 11, 13, 10, 12, 14, 11, 13, 15, 12, 14, 16,\n",
    "             9, 11, 13, 10, 12, 14, 11, 13, 15, 12, 14, 16,\n",
    "             9, 11, 13, 10, 12, 14, 11, 13, 15, 12, 14, 16,\n",
    "             9, 11, 13, 10, 12, 14, 11, 13, 15, 12, 14, 16,\n",
    "             9, 11, 13, 10, 12, 14, 11, 13, 15, 12, 14, 16]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=df).fit()\n",
    "\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ea505",
   "metadata": {},
   "source": [
    "#QNO.11 ANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4f8e80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -0.49306371945465977\n",
      "P-value: 0.6279288002855348\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper reject\n",
      "--------------------------------------------------------\n",
      "Control Experimental      1.0 0.6279 -3.261 5.261  False\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "control_scores = [82, 85, 78, 90, 88, 92, 87, 85, 80, 86]\n",
    "\n",
    "experimental_scores = [88, 90, 92, 78, 85, 88, 84, 92, 86, 80]\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "scores = np.concatenate([control_scores, experimental_scores])\n",
    "group_labels = [\"Control\"] * len(control_scores) + [\"Experimental\"] * len(experimental_scores)\n",
    "\n",
    "tukey_result = pairwise_tukeyhsd(scores, group_labels)\n",
    "\n",
    "print(tukey_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5523b9",
   "metadata": {},
   "source": [
    "#QNO.12 ANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "336d663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Anova\n",
      "==================================\n",
      "    F Value  Num DF  Den DF Pr > F\n",
      "----------------------------------\n",
      "Day  0.8946 29.0000 58.0000 0.6202\n",
      "==================================\n",
      "\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      "group1 group2  meandiff p-adj    lower    upper   reject\n",
      "--------------------------------------------------------\n",
      "     A      B    -102.1  0.262  -256.704   52.504  False\n",
      "     A      C -228.2333  0.002 -382.8373 -73.6294   True\n",
      "     B      C -126.1333 0.1322 -280.7373  28.4706  False\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "store_a_sales = np.random.randint(1000, 2000, size=30)\n",
    "store_b_sales = np.random.randint(900, 1800, size=30)\n",
    "store_c_sales = np.random.randint(800, 1700, size=30)\n",
    "\n",
    "data = {\n",
    "    'Store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
    "    'Sales': np.concatenate([store_a_sales, store_b_sales, store_c_sales]),\n",
    "    'Day': np.tile(np.arange(30), 3)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "rm_anova = AnovaRM(df, 'Sales', 'Store', within=['Day'])\n",
    "results = rm_anova.fit()\n",
    "\n",
    "print(results.summary())\n",
    "\n",
    "posthoc = sm.stats.multicomp.pairwise_tukeyhsd(df['Sales'], df['Store'])\n",
    "print(posthoc.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16540e30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
